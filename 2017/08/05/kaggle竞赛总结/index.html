<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="this is amazing"><title>kaggle竞赛总结 | Matafight's world</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">kaggle竞赛总结</h1><a id="logo" href="/.">Matafight's world</a><p class="description">点滴进步</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">kaggle竞赛总结</h1><div class="post-meta">Aug 5, 2017<span> | </span><span class="category"><a href="/categories/kaggle/">kaggle</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2017/08/05/kaggle竞赛总结/" href="/2017/08/05/kaggle竞赛总结/#comments" class="ds-thread-count"></a><div class="post-content"><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>最近刚参加了一个kaggle比赛(Mercedes-Benz Greener Manufacturing),据赛题介绍主要的任务是预测一辆刚出厂的汽车做完检测所需要的时间，从而能够合理安排检测任务，节省能源？创建一个绿色环保的世界？？<br>我的最终排名是 273/3835,进了top10%，得到了一个Bronze medal,是我得到的第一个奖牌，开心。<br>在这里总结一下参加这个比赛的收获。</p>
<h2 id="特征部分"><a href="#特征部分" class="headerlink" title="特征部分"></a>特征部分</h2><p>这个比赛的特征都是经过脱敏的，所以你不知道各个特征的具体意思，这一点对于特征工程来说就比较难受了，这个数据与在Quora比赛中使用的数据类型不同，Quora数据的一个样本是两个句子，任务是判断这两个问题相同或不相同，所以任务的很大一部分都是做特征工程，提取特征，比如两个句子的cos距离，tf-idf特征，pearson相关系数，通过word2vec提取出来的向量等等都可以用作Quora任务的特征，但是，Benz竞赛的数据只是给定的脱敏数据，具体的特征工程需要自己尝试。</p>
<p>这次比赛的重点我放在了模型融合和集成学习方面，所以特征方面探索得比较少，这也是未来需要改进的方向。<br>我的做法是对于categorical features，直接采用one-hot 编码，对于numerical features,分别使用了PCA,SVD，ICA，随机投影等方法抽取特征，并将抽取出的特征与原有特征连接在一起组成新的特征，之后的模型融合也基于这些新的特征。</p>
<p>后来第二名在讨论区中公布了他的<a href="https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36390" target="_blank" rel="noopener">解决方案</a>,他通过类似于wrapper的方式做特征选择(不同于filter方式，wrapper的feature subset的好坏由training algorihtm’s crossvalid performance决定，而filter方式的feature subset选择与training algorithm 相互独立，subset的选择是通过其他方式),我在这里贴一下他的代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.random <span class="keyword">import</span> choice</span><br><span class="line">n_elements = train.shape[<span class="number">0</span>]</span><br><span class="line">feats = train.columns.values[<span class="number">9</span>:]</span><br><span class="line">n_feats = len(feats)</span><br><span class="line">weights = np.array(np.zeros(n_feats))</span><br><span class="line">weights += <span class="number">1</span>/n_feats</span><br><span class="line"></span><br><span class="line">best_feats = []</span><br><span class="line">best_score = <span class="number">0</span></span><br><span class="line">epochs = <span class="number">3000</span>    <span class="comment"># number of rounds / feature bags</span></span><br><span class="line">n_features = <span class="number">10</span> <span class="comment"># try out different values </span></span><br><span class="line">wt_g = <span class="number">.2</span>  <span class="comment">#weight growth rate</span></span><br><span class="line">w_threshold = <span class="number">.2</span>  <span class="comment">#weight to add feature</span></span><br><span class="line">kf = KFold(n_elements, n_folds=<span class="number">3</span>, shuffle=<span class="keyword">True</span>)</span><br><span class="line">y = train[<span class="string">'y'</span>].values</span><br><span class="line">scores = []</span><br><span class="line">top_feats = np.array([])</span><br><span class="line">new_feats = np.array([])</span><br><span class="line"><span class="keyword">for</span> i, ind <span class="keyword">in</span> enumerate(list(range(epochs))):</span><br><span class="line"></span><br><span class="line">    sample_feat_ids = choice(a=n_feats, size=n_features, </span><br><span class="line">                             replace=<span class="keyword">False</span>, p=weights)</span><br><span class="line">    sample_feats = np.append(top_feats, feats[sample_feat_ids])</span><br><span class="line">    tst_P = np.array(np.zeros(n_elements))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> trn, tst <span class="keyword">in</span> kf: </span><br><span class="line">        X = train.loc[:,sample_feats]</span><br><span class="line">        trn_X, tst_X = X.iloc[trn,:], X.iloc[tst,:]</span><br><span class="line">        trn_Y, tst_Y = clipped_y[trn], clipped_y[tst]</span><br><span class="line">        <span class="comment">#mod = SVR(C=50, epsilon=3, gamma=.2)</span></span><br><span class="line">        <span class="comment">#mod = GBR(alpha=.01, n_estimators=50, max_depth=5, min_samples_leaf=15, subsample=.5, random_state=1776)</span></span><br><span class="line">        mod = RFR(n_estimators=<span class="number">100</span>, max_depth=<span class="number">12</span>, max_features=<span class="number">20</span>, min_samples_leaf=<span class="number">4</span>, n_jobs=<span class="number">2</span>, random_state=<span class="number">1776</span>)</span><br><span class="line">        mod.fit(trn_X, trn_Y)</span><br><span class="line">        tst_P[tst] = mod.predict(tst_X)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># I don't want to overfit to outliers so I am clipping all y's at 155</span></span><br><span class="line">    tst_rsq = r2(y_pred=tst_P, y_true=clipped_y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ind &gt; <span class="number">29</span>:</span><br><span class="line">        scores.append(tst_rsq)</span><br><span class="line">        ma_rsq = np.mean(scores[<span class="number">-30</span>:])</span><br><span class="line">        <span class="keyword">if</span> ind % <span class="number">25</span> == <span class="number">0</span>:</span><br><span class="line">            print(ind, ma_rsq, tst_rsq)</span><br><span class="line">        <span class="keyword">if</span> tst_rsq &gt; ma_rsq:</span><br><span class="line">            weights[sample_feat_ids] *= (<span class="number">1</span>+wt_g)</span><br><span class="line">            sum_w = np.sum(weights)</span><br><span class="line">            weights /= sum_w</span><br><span class="line">            <span class="keyword">if</span> tst_rsq &amp;gt; best_score:</span><br><span class="line">                best_score = tst_rsq</span><br><span class="line">                best_feats = sample_feats</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            weights[sample_feat_ids] *= (<span class="number">1</span>-wt_g)</span><br><span class="line">            sum_w = np.sum(weights)</span><br><span class="line">            weights /= sum_w</span><br><span class="line">        mx_w = np.max(weights)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># add feature to the top feats if weight is &amp;gt; threshold</span></span><br><span class="line">        <span class="keyword">if</span> mx_w &gt; w_threshold:</span><br><span class="line">            feat_imps = pd.Series(index = feats, data = weights)</span><br><span class="line">            new_feats = feat_imps[feat_imps &gt; w_threshold].index.values</span><br><span class="line">            top_weights = feat_imps[feat_imps &gt; w_threshold].values</span><br><span class="line">            top_feats = np.append(top_feats, new_feats)</span><br><span class="line">            feats = list(feats)</span><br><span class="line">            weights = list(weights)</span><br><span class="line">            <span class="keyword">for</span> f,w <span class="keyword">in</span> zip(new_feats,top_weights):</span><br><span class="line">                print(f, w)</span><br><span class="line">                feats.remove(f)</span><br><span class="line">                weights.remove(w)</span><br><span class="line">            n_feats = len(weights)</span><br><span class="line">            feats = np.array(feats)</span><br><span class="line">            weights = np.array(weights)</span><br><span class="line">            sum_w = np.sum(weights)</span><br><span class="line">            weights /= sum_w</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ind % <span class="number">25</span> == <span class="number">0</span>: </span><br><span class="line">            print(mx_w)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        scores.append(tst_rsq)</span><br><span class="line">        print(ind, tst_rsq)</span><br></pre></td></tr></table></figure></p>
<p>不过这种选择方法的时间复杂度还是挺高的。</p>
<h2 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a>模型选择</h2><p>我采用了stacking的集成方式(stacking 与 blending的区别在于blending首先将数据划分为两部分，其中一部分用来训练，然后用训练好的模型预测另一部分，将这一部分的预测值当成下一层的输入，而stacking则是通过cross validation的方法预测所有的数据，然后将所有预测值输入到下一层)，blending的缺点是当数据量较少的时候，第二层的训练数据太少，优点是两层数据不相关，避免过拟合效果好，但是由于stacking是采用交叉验证的方式生成预测值，所以也能避免过拟合。</p>
<p>stacking采用了如下子模型：</p>
<ul>
<li>RandomForest</li>
<li>Gbregressor</li>
<li>Lasso</li>
<li>ridge</li>
<li>SVR</li>
</ul>
<p>stacking的方式可以参考我上一篇博客，代码可以参看我的<a href="https://github.com/Matafight/Kaggle" target="_blank" rel="noopener">github</a>。</p>
<p>我最终的结果还参考了public kernel上另一个比较好的<a href="https://www.kaggle.com/hakeem/stacked-then-averaged-models-0-5697?scriptVersionId=1236940/code" target="_blank" rel="noopener">Solution</a>,基本上是将我的预测值与这个kernel的预测值做了一个平均，这也可以看作是一种集成方式吧。</p>
<p>其实我觉得stacking也算是一种黑盒子吧，把那么多方法“堆”在一起，虽然有效果，但也是说不清道不明的原因，有一种说法我觉得还是比较有道理的，第二层的模型相当于对第一层的输出做组合，组合出最好的结果,所以第二层一般采用线性组合。这就是集成的思想。</p>
<p>集成学习最重要的就是保证各个分类器有足够的diversity和accuracy，要有足够的差异性和准确性，不能都是猪队友，也不能都是同一个行业的精英。需要注意的是同一个分类器的不同参数配置也可以看作是不同的模型。</p>
<h2 id="tips"><a href="#tips" class="headerlink" title="tips"></a>tips</h2><ul>
<li><p>kernel和discussion经常会有人提供新的想法和证据来分析这个问题和数据，这是个学习数据处理的好地方。</p>
</li>
<li><p>不要太看重public LB，因为最终的结果由private LB决定，一般public LB占总测试集的20%左右，private LB的结果占80%左右，很多情况下会过拟合到public LB上去，此时最好相信本地的local CV score，特别是一些比赛可以通过public LB的反馈来获取public LB所采用测试集的分布和其他信息，比如对于二分类问题，提交全零的结果上去，如果PLB采用的评价准则为01误差，就可以得到PLB测试集的正负样本分布了，知道了样本分布就可以提高PLB上的分数了。但是这个分数对于Private LB没有意义，只会过拟合。</p>
</li>
<li><p>怎么根据样本分布提高分数呢？<br>我们知道对于类别不平衡问题有好几种解决方法。1. 重采样，降采样。2. rescaling，再缩放，比如对于logistic regression，y为样本为正例的概率， y/(1-y)&gt;1时为正例，y/(1-y)&lt;1时为负例，这个结果建立在正负样本平衡的基础上，如果正负不平衡，假设正例个数为m+，负例个数为m-,那么根据观测值得到的阈值为m+/m-， 这里假设观测值为总体值的无偏估计，所谓再缩放就是将1替换为m+/m-，重新判断正负。3.采用auc等对不平衡数据不敏感的度量方式。</p>
</li>
<li><p>特征还是比模型更重要的，模型基本上用来用去都是集成,stacking，xgboost等，如何做特征选择，如何分析特征还是最重要的。我这次这方面下的功夫比较少。</p>
</li>
<li><p>自动化，自动化，自动化脚本非常重要。</p>
</li>
<li><p>在对模型结果做weighted-averaging的时候权重该怎么选择？</p>
<ol>
<li>可以根据两个模型的cv score的比值分配权重</li>
<li>暴力搜索，然后交叉验证，虽然暴力但也是一种方法</li>
</ol>
</li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://matafight.github.io/2017/08/05/kaggle竞赛总结/" data-id="cjtmbeg6k0018o49wmduqivp7" class="article-share-link">分享到</a><div class="tags"><a href="/tags/machine-learning/">machine learning</a></div><div class="post-nav"><a href="/2017/08/29/gbdt-xgboost与lightgbm/" class="pre">gbdt,xgboost与lightgbm</a><a href="/2017/06/30/python中的编码问题/" class="next">python中的编码问题</a></div><div data-thread-key="2017/08/05/kaggle竞赛总结/" data-title="kaggle竞赛总结" data-url="http://matafight.github.io/2017/08/05/kaggle竞赛总结/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2017/08/05/kaggle竞赛总结/" data-title="kaggle竞赛总结" data-url="http://matafight.github.io/2017/08/05/kaggle竞赛总结/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://matafight.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deel-learning/">Deel learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Matlab/">Matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/git/">git</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kaggle/">kaggle</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/machine-learning/">machine learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/python/">python</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/sgd/">sgd</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/tensorflow/">tensorflow</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/vim/">vim</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/其他/">其他</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/博客本身/">博客本身</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/工具/">工具</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂记-Matlab/">杂记|Matlab</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/知乎/">知乎</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/工具/" style="font-size: 15px;">工具</a> <a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/毕设/" style="font-size: 15px;">毕设</a> <a href="/tags/bayes/" style="font-size: 15px;">bayes</a> <a href="/tags/Model-Selection/" style="font-size: 15px;">Model-Selection</a> <a href="/tags/Cython/" style="font-size: 15px;">Cython</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/kaggle/" style="font-size: 15px;">kaggle</a> <a href="/tags/machine-learning/" style="font-size: 15px;">machine learning</a> <a href="/tags/latex/" style="font-size: 15px;">latex</a> <a href="/tags/normalization/" style="font-size: 15px;">normalization</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/编码/" style="font-size: 15px;">编码</a> <a href="/tags/spider/" style="font-size: 15px;">spider</a> <a href="/tags/XGBoost/" style="font-size: 15px;">XGBoost</a> <a href="/tags/deep-learning/" style="font-size: 15px;">deep learning</a> <a href="/tags/pandas/" style="font-size: 15px;">pandas</a> <a href="/tags/c/" style="font-size: 15px;">c++</a> <a href="/tags/FAQ/" style="font-size: 15px;">FAQ</a> <a href="/tags/求职/" style="font-size: 15px;">求职</a> <a href="/tags/好的博客/" style="font-size: 15px;">好的博客</a> <a href="/tags/machien-learning/" style="font-size: 15px;">machien learning</a> <a href="/tags/数学/" style="font-size: 15px;">数学</a> <a href="/tags/正则化/" style="font-size: 15px;">正则化</a> <a href="/tags/gluon/" style="font-size: 15px;">gluon</a> <a href="/tags/矩阵/" style="font-size: 15px;">矩阵</a> <a href="/tags/hexo/" style="font-size: 15px;">hexo</a> <a href="/tags/sgd/" style="font-size: 15px;">sgd</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/18/用gluon写rnn/">用gluon写rnn</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/15/新的一年/">新的一年</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/12/git-note/">git note</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/05/Deep-Learning-Chapter16/">Deep Learning Chapter16</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/19/CNN结构的发展/">CNN结构的发展</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/25/Deep-learning-chapter10-part-1/">Deep learning chapter10</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/17/广义线性模型/">广义线性模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/29/gbdt-xgboost与lightgbm/">gbdt,xgboost与lightgbm</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/kaggle竞赛总结/">kaggle竞赛总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/30/python中的编码问题/">python中的编码问题</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://tsien.github.io/" title="tsien" target="_blank">tsien</a><ul></ul><a href="http://www.ruanyifeng.com/blog/" title="阮一峰的网络日志" target="_blank">阮一峰的网络日志</a><ul></ul><a href="http://blog.csdn.net/abcjennifer/article/category/1226975" title="Rachel Zhang的专栏" target="_blank">Rachel Zhang的专栏</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Matafight's world.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'matafight1994'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>